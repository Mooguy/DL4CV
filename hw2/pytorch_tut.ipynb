{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_data)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  2,  3],\n",
       "        [ 4,  6,  6],\n",
       "        [ 7,  8, 10]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = torch.tensor([[1,0,0],[0,1,0],[0,0,1]])\n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3],\n",
       "        [4, 4, 6],\n",
       "        [7, 8, 8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 5, 0],\n",
       "        [0, 0, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 3],\n",
       "        [4, 5, 5],\n",
       "        [5, 5, 5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.clamp_(2,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 3, 1, 0, 0],\n",
       "        [4, 5, 5, 0, 1, 0],\n",
       "        [5, 5, 5, 0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,b),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 3],\n",
       "        [4, 5, 5],\n",
       "        [5, 5, 5],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,b),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 3, 4, 5, 5, 5, 5, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 3],\n",
       "        [4, 5, 5],\n",
       "        [5, 5, 5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2, 3],\n",
       "         [4, 5, 5],\n",
       "         [5, 5, 5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze_(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze_(dim=0).squeeze_().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_to_gpu(data):\n",
    "    try:\n",
    "        return data.to('cuda')\n",
    "    except RuntimeError:\n",
    "        return data\n",
    "\n",
    "x_gpu = transfer_to_gpu(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5],\n",
       "        [ 8, 10],\n",
       "        [12, 15]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])  # Shape (3,)\n",
    "y = torch.tensor([4, 5])     # Shape (2,)\n",
    "result = torch.einsum(\"i,j->ij\", x, y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])  # Shape (2, 2)\n",
    "result = torch.einsum(\"ij->\", x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "result = torch.einsum(\"i,i->\", x, y)\n",
    "print(result)  # Output: tensor(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3, 4, 5)  # Shape (3, 4, 5)\n",
    "result = torch.einsum(\"ijk->kji\", A)\n",
    "print(result.shape)  # Output: torch.Size([5, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  7,  10],\n",
       "         [ 15,  22]],\n",
       "\n",
       "        [[ 67,  78],\n",
       "         [ 91, 106]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.tensor([[[1,2],[3,4]],\n",
    "                    [[5,6],[7,8]]])\n",
    "\n",
    "mat2 = torch.tensor([[[1,2],[3,4]],\n",
    "                    [[5,6],[7,8]]])\n",
    "\n",
    "out = torch.einsum('bnk,bkm->bnm', mat1, mat2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3493, 0.6875],\n",
       "         [0.3128, 0.8187]],\n",
       "\n",
       "        [[0.0656, 0.2721],\n",
       "         [0.8771, 0.3840]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0732, 0.7080, 0.1491, 0.8934, 0.8501, 0.8808],\n",
      "         [0.5583, 0.0190, 0.8253, 0.1859, 0.6004, 0.8518],\n",
      "         [0.6320, 0.2956, 0.4388, 0.0299, 0.7550, 0.6311],\n",
      "         [0.7194, 0.7896, 0.8093, 0.1154, 0.5958, 0.2232]],\n",
      "\n",
      "        [[0.8171, 0.9269, 0.9785, 0.5975, 0.5934, 0.0187],\n",
      "         [0.1932, 0.3177, 0.6441, 0.7828, 0.2892, 0.8618],\n",
      "         [0.6747, 0.5028, 0.5533, 0.4182, 0.0521, 0.7730],\n",
      "         [0.8694, 0.3767, 0.3975, 0.8326, 0.2360, 0.1234]],\n",
      "\n",
      "        [[0.6229, 0.6864, 0.1960, 0.9962, 0.4411, 0.3955],\n",
      "         [0.3602, 0.9446, 0.5387, 0.3753, 0.1326, 0.3168],\n",
      "         [0.6213, 0.5534, 0.5535, 0.2558, 0.2011, 0.5605],\n",
      "         [0.1420, 0.3451, 0.0519, 0.5927, 0.9380, 0.1966]],\n",
      "\n",
      "        [[0.8068, 0.7358, 0.9139, 0.7906, 0.6136, 0.2223],\n",
      "         [0.9072, 0.3482, 0.3605, 0.8288, 0.6576, 0.3309],\n",
      "         [0.1154, 0.4608, 0.1009, 0.0053, 0.4832, 0.6288],\n",
      "         [0.1196, 0.0198, 0.5463, 0.0258, 0.9369, 0.7845]]])\n",
      "tensor([[[0, 0, 1, 0, 3, 3],\n",
      "         [2, 2, 3, 2, 1, 0],\n",
      "         [1, 0, 3, 3, 3, 3],\n",
      "         [2, 3, 2, 3, 3, 2]]])\n",
      "tensor([[[0.0732, 0.7080, 0.9785, 0.8934, 0.6136, 0.2223],\n",
      "         [0.3602, 0.9446, 0.3605, 0.3753, 0.2892, 0.8518],\n",
      "         [0.6747, 0.2956, 0.1009, 0.0053, 0.4832, 0.6288],\n",
      "         [0.1420, 0.0198, 0.0519, 0.0258, 0.9369, 0.1966]]])\n"
     ]
    }
   ],
   "source": [
    "dim = 0\n",
    "src = torch.rand(4,4,6)\n",
    "index = torch.randint(0, 4, (1, 4, 6))\n",
    "\n",
    "out = torch.gather(src, dim, index)\n",
    "\n",
    "print(src)\n",
    "print(index)\n",
    "print(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "C = 10\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(INPUT_SIZE*INPUT_SIZE, 256)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(256, 512)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.fc3 = torch.nn.Linear(512, C)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)  \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "\n",
    "input = torch.randn(B, 1, INPUT_SIZE, INPUT_SIZE)\n",
    "model = MLP()\n",
    "\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(INPUT_SIZE*INPUT_SIZE, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, C)\n",
    ")\n",
    "\n",
    "output = seq_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.])\n",
    "w = torch.tensor([1.], \n",
    "    requires_grad=True)\n",
    "y = torch.tensor([3.])\n",
    "\n",
    "y_hat = w*x\n",
    "L = (y_hat - y)**2\n",
    "L.backward()\n",
    "\n",
    "print(w.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.])\n",
    "w = torch.tensor([1.], \n",
    "    requires_grad=True)\n",
    "y = torch.tensor([3.])\n",
    "\n",
    "y_hat = w*x\n",
    "L = (y_hat - y)**2\n",
    "L.backward()\n",
    "\n",
    "w.grad.zero_()\n",
    "\n",
    "L = (x * w - y)**2\n",
    "L.backward()\n",
    "\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) \n",
    "\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "B_SQRT =8\n",
    "B = B_SQRT**2\n",
    "EPOCHS = 100\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26421880/26421880 [00:00<00:00, 93458491.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29515/29515 [00:00<00:00, 204281984.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4422102/4422102 [00:00<00:00, 101424166.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5148/5148 [00:00<00:00, 41523609.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms  # Correct imports for datasets and transforms\n",
    "\n",
    "# Transform to convert images to tensors\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Load the training data\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform  # Use the transform\n",
    ")\n",
    "\n",
    "# Load the test data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform  # Use the transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=B, shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(test_data, batch_size=B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(INPUT_SIZE*INPUT_SIZE, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, C)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 2.0981\n",
      "Validation Loss: 1.9689, Accuracy: 0.4780\n",
      "Epoch 2/100\n",
      "Train Loss: 1.7880\n",
      "Validation Loss: 1.6043, Accuracy: 0.5674\n",
      "Epoch 3/100\n",
      "Train Loss: 1.4417\n",
      "Validation Loss: 1.3081, Accuracy: 0.6094\n",
      "Epoch 4/100\n",
      "Train Loss: 1.2034\n",
      "Validation Loss: 1.1260, Accuracy: 0.6298\n",
      "Epoch 5/100\n",
      "Train Loss: 1.0561\n",
      "Validation Loss: 1.0111, Accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "Train Loss: 0.9602\n",
      "Validation Loss: 0.9337, Accuracy: 0.6645\n",
      "Epoch 7/100\n",
      "Train Loss: 0.8927\n",
      "Validation Loss: 0.8782, Accuracy: 0.6759\n",
      "Epoch 8/100\n",
      "Train Loss: 0.8430\n",
      "Validation Loss: 0.8357, Accuracy: 0.6922\n",
      "Epoch 9/100\n",
      "Train Loss: 0.8045\n",
      "Validation Loss: 0.8022, Accuracy: 0.7030\n",
      "Epoch 10/100\n",
      "Train Loss: 0.7732\n",
      "Validation Loss: 0.7754, Accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "Train Loss: 0.7473\n",
      "Validation Loss: 0.7519, Accuracy: 0.7265\n",
      "Epoch 12/100\n",
      "Train Loss: 0.7249\n",
      "Validation Loss: 0.7313, Accuracy: 0.7376\n",
      "Epoch 13/100\n",
      "Train Loss: 0.7050\n",
      "Validation Loss: 0.7131, Accuracy: 0.7464\n",
      "Epoch 14/100\n",
      "Train Loss: 0.6874\n",
      "Validation Loss: 0.6968, Accuracy: 0.7473\n",
      "Epoch 15/100\n",
      "Train Loss: 0.6711\n",
      "Validation Loss: 0.6817, Accuracy: 0.7555\n",
      "Epoch 16/100\n",
      "Train Loss: 0.6562\n",
      "Validation Loss: 0.6677, Accuracy: 0.7617\n",
      "Epoch 17/100\n",
      "Train Loss: 0.6423\n",
      "Validation Loss: 0.6549, Accuracy: 0.7699\n",
      "Epoch 18/100\n",
      "Train Loss: 0.6295\n",
      "Validation Loss: 0.6436, Accuracy: 0.7714\n",
      "Epoch 19/100\n",
      "Train Loss: 0.6177\n",
      "Validation Loss: 0.6322, Accuracy: 0.7794\n",
      "Epoch 20/100\n",
      "Train Loss: 0.6067\n",
      "Validation Loss: 0.6220, Accuracy: 0.7811\n",
      "Epoch 21/100\n",
      "Train Loss: 0.5964\n",
      "Validation Loss: 0.6126, Accuracy: 0.7848\n",
      "Epoch 22/100\n",
      "Train Loss: 0.5874\n",
      "Validation Loss: 0.6046, Accuracy: 0.7883\n",
      "Epoch 23/100\n",
      "Train Loss: 0.5782\n",
      "Validation Loss: 0.5975, Accuracy: 0.7904\n",
      "Epoch 24/100\n",
      "Train Loss: 0.5702\n",
      "Validation Loss: 0.5889, Accuracy: 0.7927\n",
      "Epoch 25/100\n",
      "Train Loss: 0.5625\n",
      "Validation Loss: 0.5814, Accuracy: 0.7945\n",
      "Epoch 26/100\n",
      "Train Loss: 0.5551\n",
      "Validation Loss: 0.5750, Accuracy: 0.7978\n",
      "Epoch 27/100\n",
      "Train Loss: 0.5482\n",
      "Validation Loss: 0.5701, Accuracy: 0.7992\n",
      "Epoch 28/100\n",
      "Train Loss: 0.5420\n",
      "Validation Loss: 0.5632, Accuracy: 0.8043\n",
      "Epoch 29/100\n",
      "Train Loss: 0.5359\n",
      "Validation Loss: 0.5575, Accuracy: 0.8045\n",
      "Epoch 30/100\n",
      "Train Loss: 0.5304\n",
      "Validation Loss: 0.5536, Accuracy: 0.8056\n",
      "Epoch 31/100\n",
      "Train Loss: 0.5249\n",
      "Validation Loss: 0.5478, Accuracy: 0.8076\n",
      "Epoch 32/100\n",
      "Train Loss: 0.5202\n",
      "Validation Loss: 0.5431, Accuracy: 0.8093\n",
      "Epoch 33/100\n",
      "Train Loss: 0.5153\n",
      "Validation Loss: 0.5398, Accuracy: 0.8110\n",
      "Epoch 34/100\n",
      "Train Loss: 0.5108\n",
      "Validation Loss: 0.5389, Accuracy: 0.8109\n",
      "Epoch 35/100\n",
      "Train Loss: 0.5067\n",
      "Validation Loss: 0.5322, Accuracy: 0.8134\n",
      "Epoch 36/100\n",
      "Train Loss: 0.5029\n",
      "Validation Loss: 0.5279, Accuracy: 0.8125\n",
      "Epoch 37/100\n",
      "Train Loss: 0.4993\n",
      "Validation Loss: 0.5239, Accuracy: 0.8156\n",
      "Epoch 38/100\n",
      "Train Loss: 0.4955\n",
      "Validation Loss: 0.5219, Accuracy: 0.8161\n",
      "Epoch 39/100\n",
      "Train Loss: 0.4924\n",
      "Validation Loss: 0.5179, Accuracy: 0.8168\n",
      "Epoch 40/100\n",
      "Train Loss: 0.4889\n",
      "Validation Loss: 0.5153, Accuracy: 0.8165\n",
      "Epoch 41/100\n",
      "Train Loss: 0.4860\n",
      "Validation Loss: 0.5153, Accuracy: 0.8147\n",
      "Epoch 42/100\n",
      "Train Loss: 0.4832\n",
      "Validation Loss: 0.5107, Accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "Train Loss: 0.4805\n",
      "Validation Loss: 0.5074, Accuracy: 0.8216\n",
      "Epoch 44/100\n",
      "Train Loss: 0.4776\n",
      "Validation Loss: 0.5069, Accuracy: 0.8203\n",
      "Epoch 45/100\n",
      "Train Loss: 0.4750\n",
      "Validation Loss: 0.5051, Accuracy: 0.8225\n",
      "Epoch 46/100\n",
      "Train Loss: 0.4725\n",
      "Validation Loss: 0.5012, Accuracy: 0.8230\n",
      "Epoch 47/100\n",
      "Train Loss: 0.4700\n",
      "Validation Loss: 0.4993, Accuracy: 0.8231\n",
      "Epoch 48/100\n",
      "Train Loss: 0.4677\n",
      "Validation Loss: 0.4975, Accuracy: 0.8246\n",
      "Epoch 49/100\n",
      "Train Loss: 0.4658\n",
      "Validation Loss: 0.4950, Accuracy: 0.8256\n",
      "Epoch 50/100\n",
      "Train Loss: 0.4635\n",
      "Validation Loss: 0.4941, Accuracy: 0.8244\n",
      "Epoch 51/100\n",
      "Train Loss: 0.4615\n",
      "Validation Loss: 0.4907, Accuracy: 0.8267\n",
      "Epoch 52/100\n",
      "Train Loss: 0.4594\n",
      "Validation Loss: 0.4892, Accuracy: 0.8270\n",
      "Epoch 53/100\n",
      "Train Loss: 0.4577\n",
      "Validation Loss: 0.4890, Accuracy: 0.8246\n",
      "Epoch 54/100\n",
      "Train Loss: 0.4557\n",
      "Validation Loss: 0.4878, Accuracy: 0.8271\n",
      "Epoch 55/100\n",
      "Train Loss: 0.4537\n",
      "Validation Loss: 0.4843, Accuracy: 0.8295\n",
      "Epoch 56/100\n",
      "Train Loss: 0.4521\n",
      "Validation Loss: 0.4843, Accuracy: 0.8275\n",
      "Epoch 57/100\n",
      "Train Loss: 0.4504\n",
      "Validation Loss: 0.4819, Accuracy: 0.8295\n",
      "Epoch 58/100\n",
      "Train Loss: 0.4488\n",
      "Validation Loss: 0.4794, Accuracy: 0.8301\n",
      "Epoch 59/100\n",
      "Train Loss: 0.4470\n",
      "Validation Loss: 0.4786, Accuracy: 0.8308\n",
      "Epoch 60/100\n",
      "Train Loss: 0.4456\n",
      "Validation Loss: 0.4772, Accuracy: 0.8306\n",
      "Epoch 61/100\n",
      "Train Loss: 0.4439\n",
      "Validation Loss: 0.4774, Accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "Train Loss: 0.4425\n",
      "Validation Loss: 0.4741, Accuracy: 0.8334\n",
      "Epoch 63/100\n",
      "Train Loss: 0.4411\n",
      "Validation Loss: 0.4754, Accuracy: 0.8315\n",
      "Epoch 64/100\n",
      "Train Loss: 0.4394\n",
      "Validation Loss: 0.4716, Accuracy: 0.8338\n",
      "Epoch 65/100\n",
      "Train Loss: 0.4384\n",
      "Validation Loss: 0.4708, Accuracy: 0.8339\n",
      "Epoch 66/100\n",
      "Train Loss: 0.4369\n",
      "Validation Loss: 0.4693, Accuracy: 0.8339\n",
      "Epoch 67/100\n",
      "Train Loss: 0.4357\n",
      "Validation Loss: 0.4693, Accuracy: 0.8334\n",
      "Epoch 68/100\n",
      "Train Loss: 0.4342\n",
      "Validation Loss: 0.4670, Accuracy: 0.8348\n",
      "Epoch 69/100\n",
      "Train Loss: 0.4330\n",
      "Validation Loss: 0.4660, Accuracy: 0.8341\n",
      "Epoch 70/100\n",
      "Train Loss: 0.4317\n",
      "Validation Loss: 0.4645, Accuracy: 0.8348\n",
      "Epoch 71/100\n",
      "Train Loss: 0.4306\n",
      "Validation Loss: 0.4639, Accuracy: 0.8360\n",
      "Epoch 72/100\n",
      "Train Loss: 0.4292\n",
      "Validation Loss: 0.4625, Accuracy: 0.8356\n",
      "Epoch 73/100\n",
      "Train Loss: 0.4281\n",
      "Validation Loss: 0.4627, Accuracy: 0.8365\n",
      "Epoch 74/100\n",
      "Train Loss: 0.4268\n",
      "Validation Loss: 0.4623, Accuracy: 0.8343\n",
      "Epoch 75/100\n",
      "Train Loss: 0.4259\n",
      "Validation Loss: 0.4599, Accuracy: 0.8371\n",
      "Epoch 76/100\n",
      "Train Loss: 0.4245\n",
      "Validation Loss: 0.4595, Accuracy: 0.8370\n",
      "Epoch 77/100\n",
      "Train Loss: 0.4236\n",
      "Validation Loss: 0.4590, Accuracy: 0.8366\n",
      "Epoch 78/100\n",
      "Train Loss: 0.4223\n",
      "Validation Loss: 0.4571, Accuracy: 0.8372\n",
      "Epoch 79/100\n",
      "Train Loss: 0.4214\n",
      "Validation Loss: 0.4569, Accuracy: 0.8384\n",
      "Epoch 80/100\n",
      "Train Loss: 0.4202\n",
      "Validation Loss: 0.4553, Accuracy: 0.8387\n",
      "Epoch 81/100\n",
      "Train Loss: 0.4189\n",
      "Validation Loss: 0.4546, Accuracy: 0.8374\n",
      "Epoch 82/100\n",
      "Train Loss: 0.4180\n",
      "Validation Loss: 0.4529, Accuracy: 0.8390\n",
      "Epoch 83/100\n",
      "Train Loss: 0.4168\n",
      "Validation Loss: 0.4526, Accuracy: 0.8403\n",
      "Epoch 84/100\n",
      "Train Loss: 0.4160\n",
      "Validation Loss: 0.4524, Accuracy: 0.8398\n",
      "Epoch 85/100\n",
      "Train Loss: 0.4150\n",
      "Validation Loss: 0.4519, Accuracy: 0.8393\n",
      "Epoch 86/100\n",
      "Train Loss: 0.4141\n",
      "Validation Loss: 0.4516, Accuracy: 0.8399\n",
      "Epoch 87/100\n",
      "Train Loss: 0.4131\n",
      "Validation Loss: 0.4519, Accuracy: 0.8386\n",
      "Epoch 88/100\n",
      "Train Loss: 0.4120\n",
      "Validation Loss: 0.4476, Accuracy: 0.8412\n",
      "Epoch 89/100\n",
      "Train Loss: 0.4110\n",
      "Validation Loss: 0.4472, Accuracy: 0.8410\n",
      "Epoch 90/100\n",
      "Train Loss: 0.4101\n",
      "Validation Loss: 0.4487, Accuracy: 0.8395\n",
      "Epoch 91/100\n",
      "Train Loss: 0.4090\n",
      "Validation Loss: 0.4464, Accuracy: 0.8419\n",
      "Epoch 92/100\n",
      "Train Loss: 0.4081\n",
      "Validation Loss: 0.4460, Accuracy: 0.8414\n",
      "Epoch 93/100\n",
      "Train Loss: 0.4072\n",
      "Validation Loss: 0.4521, Accuracy: 0.8367\n",
      "Epoch 94/100\n",
      "Train Loss: 0.4063\n",
      "Validation Loss: 0.4439, Accuracy: 0.8423\n",
      "Epoch 95/100\n",
      "Train Loss: 0.4055\n",
      "Validation Loss: 0.4436, Accuracy: 0.8421\n",
      "Epoch 96/100\n",
      "Train Loss: 0.4045\n",
      "Validation Loss: 0.4417, Accuracy: 0.8430\n",
      "Epoch 97/100\n",
      "Train Loss: 0.4037\n",
      "Validation Loss: 0.4415, Accuracy: 0.8438\n",
      "Epoch 98/100\n",
      "Train Loss: 0.4027\n",
      "Validation Loss: 0.4401, Accuracy: 0.8450\n",
      "Epoch 99/100\n",
      "Train Loss: 0.4018\n",
      "Validation Loss: 0.4403, Accuracy: 0.8446\n",
      "Epoch 100/100\n",
      "Train Loss: 0.4009\n",
      "Validation Loss: 0.4396, Accuracy: 0.8432\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the training loop\n",
    "def train_loop(dataloader, model, criteria, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Move data to the specified device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = criteria(pred, y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# Define the validation loop\n",
    "@torch.no_grad()  # Disable gradient computation for validation\n",
    "def val_loop(dataloader, model, criteria, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        # Move data to the specified device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = criteria(pred, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_labels = pred.argmax(dim=1)\n",
    "        correct += (predicted_labels == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# Training loop across epochs\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}/{EPOCHS}\")\n",
    "    train_res = train_loop(train_dataloader, model, criteria, optimizer, device)\n",
    "    val_res = val_loop(val_dataloader, model, criteria, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

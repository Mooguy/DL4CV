{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, w, b=None, padding=0, stride=1, dilation=1, groups=1, ctx=None):\n",
    "  \"\"\"A differentiable convolution of 2d tensors.\n",
    "\n",
    "  Note: Read this following documentation regarding the output's shape.\n",
    "  https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "\n",
    "  Backward call:\n",
    "    backward_fn: conv2d_backward\n",
    "    args: y, x, w, b, padding, stride, dilation\n",
    "\n",
    "  Args:\n",
    "    x (torch.Tensor): The input tensor.\n",
    "      Has shape `(batch_size, in_channels, height, width)`.\n",
    "    w (torch.Tensor): The weight tensor.\n",
    "      Has shape `(out_channels, in_channels, kernel_height, kernel_width)`.\n",
    "    b (torch.Tensor): The bias tensor. Has shape `(out_channels,)`.\n",
    "    padding (Tuple[int, int] or int, Optional): The padding in each dimension (height, width).\n",
    "      Defaults to 0.\n",
    "    stride (Tuple[int, int] or int, Optional): The stride in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    dilation (Tuple[int, int] or int, Optional): The dilation in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    groups (int, Optional): Number of groups. Defaults to 1.\n",
    "    ctx (List, optional): The autograd context. Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    y (torch.Tensor): The output tensor.\n",
    "      Has shape `(batch_size, out_channels, out_height, out_width)`.\n",
    "  \"\"\"\n",
    "  assert w.size(0) % groups == 0, \\\n",
    "    f'expected w.size(0)={w.size(0)} to be divisible by groups={groups}'\n",
    "  assert x.size(1) % groups == 0, \\\n",
    "    f'expected x.size(1)={x.size(1)} to be divisible by groups={groups}'\n",
    "  assert x.size(1) // groups == w.size(1), \\\n",
    "    f'expected w.size(1)={w.size(1)} to be x.size(1)//groups={x.size(1)}//{groups}'\n",
    "\n",
    "  # BEGIN SOLUTION\n",
    "  # extract and parse input\n",
    "  if b is None:\n",
    "    b = torch.zeros(out_channels, dtype=x.dtype, device=x.device)\n",
    "  #Extract input dimensions :\n",
    "  batch_size, _, height, width = x.shape\n",
    "  #Extract weight dimensions:\n",
    "  out_channels, _, kernel_height, kernel_width = w.shape\n",
    "  in_channels = w.shape[1] * groups\n",
    "  padding_h, padding_w = _pair(padding) if type(padding) is int else padding\n",
    "  stride_h, stride_w = _pair(stride) if type(stride) is int else stride\n",
    "  dilation_h, dilation_w = _pair(dilation) if type(dilation) is int else dilation\n",
    "  out_height = int(1 + ((height + 2*padding_h - dilation_h * (kernel_height - 1) - 1) / (stride_h)))\n",
    "  out_width = int(1 + ((width + 2*padding_w - dilation_w * (kernel_width - 1) - 1) / (stride_w)))\n",
    "  \n",
    "  # unfold x and split to groups\n",
    "  patches = unfold(x, (kernel_height, kernel_width),\n",
    "                    dilation=dilation,\n",
    "                    padding=padding, \n",
    "                    stride=stride)\n",
    "  patches = patches.reshape(batch_size, in_channels, kernel_height*kernel_width, out_height*out_width)\n",
    "  patches_group_split = torch.stack(patches.chunk(chunks=groups, dim=1), dim=1)\n",
    "  patches_group_split = patches_group_split.reshape(batch_size, groups, int(in_channels/groups)*kernel_height*kernel_width, out_height*out_width)\n",
    "  \n",
    "  # split w to groups\n",
    "  w_group_split = w.reshape(out_channels, int(in_channels/groups)*kernel_height*kernel_width)\n",
    "  w_group_split = torch.stack(w_group_split.chunk(chunks=groups, dim=0))\n",
    "  w_group_split = w_group_split.reshape(1, groups, int(out_channels/groups), int(in_channels/groups)*kernel_height*kernel_width)\n",
    "  \n",
    "  # compute convolution as matrix multiplication\n",
    "  convolved_patches = w_group_split @ patches_group_split\n",
    "  convolved_patches = convolved_patches.reshape(batch_size, out_channels, out_height, out_width)\n",
    "  convolved_patches += b.reshape(1, -1, 1, 1)\n",
    "\n",
    "  y = convolved_patches\n",
    "\n",
    "  if ctx is not None:\n",
    "    ctx += [(conv2d_backward, [y, x, w, b, padding, stride, dilation, groups])]\n",
    "  \n",
    "  return y\n",
    "  # END SOLUTION\n",
    "\n",
    "\n",
    "def conv2d_backward(y, x, w, b, padding, stride, dilation, groups):\n",
    "  \"\"\"Backward computation of `conv2d`.\n",
    "\n",
    "  Propagates the gradients of `y` (in `y.grad`) to `x`, `w` and `b` (if `b` is not None),\n",
    "  and accumulates them in `x.grad`, `w.grad` and `b.grad`, respectively.\n",
    "\n",
    "  Args:\n",
    "    y (torch.Tensor): The output tensor.\n",
    "      Has shape `(batch_size, out_channels, out_height, out_width)`.\n",
    "    x (torch.Tensor): The input tensor.\n",
    "      Has shape `(batch_size, in_channels, height, width)`.\n",
    "    w (torch.Tensor): The weight tensor.\n",
    "      Has shape `(out_channels, in_channels, kernel_height, kernel_width)`.\n",
    "    b (torch.Tensor): The bias tensor. Has shape `(out_channels,)`.\n",
    "    padding (Tuple[int, int] or int, Optional): The padding in each dimension (height, width).\n",
    "      Defaults to 0.\n",
    "    stride (Tuple[int, int] or int, Optional): The stride in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    dilation (Tuple[int, int] or int, Optional): The dilation in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    groups (int, Optional): Number of groups. Defaults to 1.\n",
    "  \"\"\"\n",
    "  # BEGIN SOLUTION\n",
    "  # extract and parse input\n",
    "  batch_size, _, height, width = x.shape\n",
    "  out_channels, _, kernel_height, kernel_width = w.shape\n",
    "  in_channels = w.shape[1] * groups\n",
    "  padding_h, padding_w = _pair(padding) if type(padding) is int else padding\n",
    "  stride_h, stride_w = _pair(stride) if type(stride) is int else stride\n",
    "  dilation_h, dilation_w = _pair(dilation) if type(dilation) is int else dilation\n",
    "  out_height = int(1 + ((height + 2*padding_h - dilation_h * (kernel_height - 1) - 1) / (stride_h)))\n",
    "  out_width = int(1 + ((width + 2*padding_w - dilation_w * (kernel_width - 1) - 1) / (stride_w)))\n",
    "  \n",
    "  # unfold x and split to groups\n",
    "  patches = unfold(x, (kernel_height, kernel_width),\n",
    "                    dilation=dilation,\n",
    "                    padding=padding, \n",
    "                    stride=stride)\n",
    "  patches = patches.reshape(batch_size, in_channels, kernel_height*kernel_width, out_height*out_width)\n",
    "  patches = patches.permute([0, 3, 1, 2])\n",
    "  patches_group_split = torch.stack(patches.chunk(chunks=groups, dim=2), dim=0)\n",
    "  patches_group_split = patches_group_split.reshape(groups, batch_size*out_height*out_width, int(in_channels/groups)*kernel_height*kernel_width)\n",
    "\n",
    "  # b.grad\n",
    "  b.grad += y.grad.sum([0, 2, 3])\n",
    "\n",
    "  # w.grad\n",
    "  y_grad_permuted = y.grad.permute([1, 0, 2, 3])\n",
    "  y_grad_permuted = y_grad_permuted.reshape(out_channels, batch_size*out_height*out_width)\n",
    "  y_grad_permuted_group_split = torch.stack(y_grad_permuted.chunk(chunks=groups, dim=0), dim=0)\n",
    "  w_grad_permuted = y_grad_permuted_group_split.matmul(patches_group_split)\n",
    "  w.grad += w_grad_permuted.reshape(out_channels, int(in_channels/groups), kernel_height, kernel_width)\n",
    "\n",
    "  # patches.grad (unfolded x)\n",
    "  y_grad_permuted_group_split = y_grad_permuted_group_split.permute([0, 2, 1])\n",
    "  w_permuted = w.reshape(out_channels, -1)\n",
    "  w_permuted_group_split = torch.stack(w_permuted.chunk(chunks=groups, dim=0), dim=0)\n",
    "  patches_grad_group_split = y_grad_permuted_group_split.matmul(w_permuted_group_split)\n",
    "\n",
    "  # x.grad (fold the reshaped patches.grad)\n",
    "  patches_grad_group_split = patches_grad_group_split.reshape(groups, batch_size*out_height*out_width, int(in_channels/groups), kernel_height*kernel_width)\n",
    "  patches_grad_group_split = patches_grad_group_split.permute([1, 0, 2, 3])\n",
    "  patches_grad_group_split = patches_grad_group_split.reshape(batch_size, out_height*out_width, in_channels*kernel_height*kernel_width)\n",
    "  patches_grad_group_split = patches_grad_group_split.permute([0, 2, 1])\n",
    "  x.grad += fold(patches_grad_group_split, \n",
    "                output_size=(height, width), \n",
    "                kernel_size=(kernel_height, kernel_width),\n",
    "                dilation=dilation,\n",
    "                padding=padding, \n",
    "                stride=stride)\n",
    "  # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.modules.utils import _pair, _ntuple\n",
    "\n",
    "_pair(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import unfold, fold\n",
    "import torch\n",
    "\n",
    "#make a 64*64 image with 3 channels and 1 batch:\n",
    "x = torch.tensor([[[[1., 2., 3., 4.],\n",
    "                    [5., 6., 7., 8.],\n",
    "                    [9., 10., 11., 12.],\n",
    "                    [13., 14., 15., 16.]],\n",
    "                   [[17., 18., 19., 20.],\n",
    "                    [21., 22., 23., 24.],\n",
    "                    [25., 26., 27., 28.],\n",
    "                    [29., 30., 31., 32.]],\n",
    "                   [[33., 34., 35., 36.],\n",
    "                    [37., 38., 39., 40.],\n",
    "                    [41., 42., 43., 44.],\n",
    "                    [45., 46., 47., 48.]]]])\n",
    "\n",
    "w = torch.tensor([[[[1., 2.],\n",
    "                    [3., 4.],\n",
    "                    [5., 6.]],\n",
    "                   [[7., 8.],\n",
    "                    [9., 10.],\n",
    "                    [11., 12.]],\n",
    "                   [[13., 14.],\n",
    "                    [15., 16.],\n",
    "                    [17., 18.]]],\n",
    "                  [[[19., 20.],\n",
    "                    [21., 22.],\n",
    "                    [23., 24.]],\n",
    "                   [[25., 26.],\n",
    "                    [27., 28.],\n",
    "                    [29., 30.]],\n",
    "                   [[31., 32.],\n",
    "                    [33., 34.],\n",
    "                    [35., 36.]]]])\n",
    "\n",
    "out_channels, _, kernel_height, kernel_width = w.shape\n",
    "\n",
    "padding=0\n",
    "stride=1\n",
    "dilation=1\n",
    "groups = 1\n",
    "\n",
    "#Extract input dimensions :\n",
    "batch_size, _, height, width = x.shape\n",
    "#Extract weight dimensions:\n",
    "out_channels, _, kernel_height, kernel_width = w.shape\n",
    "in_channels = w.shape[1] * groups\n",
    "\n",
    "pad_h, pad_w = _pair(padding) if type(padding) is int else padding\n",
    "stride_h, stride_w = _pair(stride) if type(stride) is int else stride\n",
    "dil_h, dil_w = _pair(dilation) if type(dilation) is int else dilation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3, 6, 12]' is invalid for input of size 108",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m out_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m ((width \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m pad_w \u001b[38;5;241m-\u001b[39m dil_w \u001b[38;5;241m*\u001b[39m (kernel_width \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (stride_w)))\n\u001b[0;32m      4\u001b[0m patches \u001b[38;5;241m=\u001b[39m unfold(x, (kernel_height, kernel_width),\n\u001b[0;32m      5\u001b[0m                 dilation\u001b[38;5;241m=\u001b[39mdilation,\n\u001b[0;32m      6\u001b[0m                 padding\u001b[38;5;241m=\u001b[39mpadding, \n\u001b[0;32m      7\u001b[0m                 stride\u001b[38;5;241m=\u001b[39mstride)\n\u001b[1;32m----> 9\u001b[0m patches \u001b[38;5;241m=\u001b[39m patches\u001b[38;5;241m.\u001b[39mreshape(batch_size, in_channels, kernel_height\u001b[38;5;241m*\u001b[39mkernel_width, out_height\u001b[38;5;241m*\u001b[39mout_width)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 3, 6, 12]' is invalid for input of size 108"
     ]
    }
   ],
   "source": [
    "out_height = int(1 + ((height + 2 * pad_h - pad_w * (kernel_height - 1) - 1) / (stride_h)))\n",
    "out_width = int(1 + ((width + 2 * pad_w - dil_w * (kernel_width - 1) - 1) / (stride_w)))\n",
    "\n",
    "patches = unfold(x, (kernel_height, kernel_width),\n",
    "                dilation=dilation,\n",
    "                padding=padding, \n",
    "                stride=stride)\n",
    "\n",
    "patches = patches.reshape(batch_size, in_channels, kernel_height*kernel_width, out_height*out_width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x): torch.Size([1, 3, 5, 5])\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.,  9.],\n",
      "          [10., 11., 12., 13., 14.],\n",
      "          [15., 16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23., 24.]],\n",
      "\n",
      "         [[25., 26., 27., 28., 29.],\n",
      "          [30., 31., 32., 33., 34.],\n",
      "          [35., 36., 37., 38., 39.],\n",
      "          [40., 41., 42., 43., 44.],\n",
      "          [45., 46., 47., 48., 49.]],\n",
      "\n",
      "         [[50., 51., 52., 53., 54.],\n",
      "          [55., 56., 57., 58., 59.],\n",
      "          [60., 61., 62., 63., 64.],\n",
      "          [65., 66., 67., 68., 69.],\n",
      "          [70., 71., 72., 73., 74.]]]])\n",
      "\n",
      "Unfolded Input (patches): torch.Size([1, 27, 25])\n",
      "tensor([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,  7.,\n",
      "           8.,  0., 10., 11., 12., 13.,  0., 15., 16., 17., 18.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,\n",
      "           9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,  9.,\n",
      "           0., 11., 12., 13., 14.,  0., 16., 17., 18., 19.,  0.],\n",
      "         [ 0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,  7.,  8.,  0., 10., 11., 12.,\n",
      "          13.,  0., 15., 16., 17., 18.,  0., 20., 21., 22., 23.],\n",
      "         [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "          14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.],\n",
      "         [ 1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,  9.,  0., 11., 12., 13., 14.,\n",
      "           0., 16., 17., 18., 19.,  0., 21., 22., 23., 24.,  0.],\n",
      "         [ 0.,  5.,  6.,  7.,  8.,  0., 10., 11., 12., 13.,  0., 15., 16., 17.,\n",
      "          18.,  0., 20., 21., 22., 23.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18.,\n",
      "          19., 20., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [ 6.,  7.,  8.,  9.,  0., 11., 12., 13., 14.,  0., 16., 17., 18., 19.,\n",
      "           0., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0., 25., 26., 27., 28.,  0., 30., 31., 32.,\n",
      "          33.,  0., 35., 36., 37., 38.,  0., 40., 41., 42., 43.],\n",
      "         [ 0.,  0.,  0.,  0.,  0., 25., 26., 27., 28., 29., 30., 31., 32., 33.,\n",
      "          34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.],\n",
      "         [ 0.,  0.,  0.,  0.,  0., 26., 27., 28., 29.,  0., 31., 32., 33., 34.,\n",
      "           0., 36., 37., 38., 39.,  0., 41., 42., 43., 44.,  0.],\n",
      "         [ 0., 25., 26., 27., 28.,  0., 30., 31., 32., 33.,  0., 35., 36., 37.,\n",
      "          38.,  0., 40., 41., 42., 43.,  0., 45., 46., 47., 48.],\n",
      "         [25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
      "          39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
      "         [26., 27., 28., 29.,  0., 31., 32., 33., 34.,  0., 36., 37., 38., 39.,\n",
      "           0., 41., 42., 43., 44.,  0., 46., 47., 48., 49.,  0.],\n",
      "         [ 0., 30., 31., 32., 33.,  0., 35., 36., 37., 38.,  0., 40., 41., 42.,\n",
      "          43.,  0., 45., 46., 47., 48.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43.,\n",
      "          44., 45., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [31., 32., 33., 34.,  0., 36., 37., 38., 39.,  0., 41., 42., 43., 44.,\n",
      "           0., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0., 50., 51., 52., 53.,  0., 55., 56., 57.,\n",
      "          58.,  0., 60., 61., 62., 63.,  0., 65., 66., 67., 68.],\n",
      "         [ 0.,  0.,  0.,  0.,  0., 50., 51., 52., 53., 54., 55., 56., 57., 58.,\n",
      "          59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
      "         [ 0.,  0.,  0.,  0.,  0., 51., 52., 53., 54.,  0., 56., 57., 58., 59.,\n",
      "           0., 61., 62., 63., 64.,  0., 66., 67., 68., 69.,  0.],\n",
      "         [ 0., 50., 51., 52., 53.,  0., 55., 56., 57., 58.,  0., 60., 61., 62.,\n",
      "          63.,  0., 65., 66., 67., 68.,  0., 70., 71., 72., 73.],\n",
      "         [50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62., 63.,\n",
      "          64., 65., 66., 67., 68., 69., 70., 71., 72., 73., 74.],\n",
      "         [51., 52., 53., 54.,  0., 56., 57., 58., 59.,  0., 61., 62., 63., 64.,\n",
      "           0., 66., 67., 68., 69.,  0., 71., 72., 73., 74.,  0.],\n",
      "         [ 0., 55., 56., 57., 58.,  0., 60., 61., 62., 63.,  0., 65., 66., 67.,\n",
      "          68.,  0., 70., 71., 72., 73.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68.,\n",
      "          69., 70., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.],\n",
      "         [56., 57., 58., 59.,  0., 61., 62., 63., 64.,  0., 66., 67., 68., 69.,\n",
      "           0., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.,  0.]]])\n",
      "\n",
      "Reshaped Patches for Groups: torch.Size([1, 3, 9, 25])\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,  7.,\n",
      "            8.,  0., 10., 11., 12., 13.,  0., 15., 16., 17., 18.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,\n",
      "            9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,  9.,\n",
      "            0., 11., 12., 13., 14.,  0., 16., 17., 18., 19.,  0.],\n",
      "          [ 0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,  7.,  8.,  0., 10., 11., 12.,\n",
      "           13.,  0., 15., 16., 17., 18.,  0., 20., 21., 22., 23.],\n",
      "          [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "           14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.],\n",
      "          [ 1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,  9.,  0., 11., 12., 13., 14.,\n",
      "            0., 16., 17., 18., 19.,  0., 21., 22., 23., 24.,  0.],\n",
      "          [ 0.,  5.,  6.,  7.,  8.,  0., 10., 11., 12., 13.,  0., 15., 16., 17.,\n",
      "           18.,  0., 20., 21., 22., 23.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18.,\n",
      "           19., 20., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [ 6.,  7.,  8.,  9.,  0., 11., 12., 13., 14.,  0., 16., 17., 18., 19.,\n",
      "            0., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0., 25., 26., 27., 28.,  0., 30., 31., 32.,\n",
      "           33.,  0., 35., 36., 37., 38.,  0., 40., 41., 42., 43.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., 25., 26., 27., 28., 29., 30., 31., 32., 33.,\n",
      "           34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., 26., 27., 28., 29.,  0., 31., 32., 33., 34.,\n",
      "            0., 36., 37., 38., 39.,  0., 41., 42., 43., 44.,  0.],\n",
      "          [ 0., 25., 26., 27., 28.,  0., 30., 31., 32., 33.,  0., 35., 36., 37.,\n",
      "           38.,  0., 40., 41., 42., 43.,  0., 45., 46., 47., 48.],\n",
      "          [25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
      "           39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
      "          [26., 27., 28., 29.,  0., 31., 32., 33., 34.,  0., 36., 37., 38., 39.,\n",
      "            0., 41., 42., 43., 44.,  0., 46., 47., 48., 49.,  0.],\n",
      "          [ 0., 30., 31., 32., 33.,  0., 35., 36., 37., 38.,  0., 40., 41., 42.,\n",
      "           43.,  0., 45., 46., 47., 48.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43.,\n",
      "           44., 45., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [31., 32., 33., 34.,  0., 36., 37., 38., 39.,  0., 41., 42., 43., 44.,\n",
      "            0., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.,  0., 50., 51., 52., 53.,  0., 55., 56., 57.,\n",
      "           58.,  0., 60., 61., 62., 63.,  0., 65., 66., 67., 68.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., 50., 51., 52., 53., 54., 55., 56., 57., 58.,\n",
      "           59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
      "          [ 0.,  0.,  0.,  0.,  0., 51., 52., 53., 54.,  0., 56., 57., 58., 59.,\n",
      "            0., 61., 62., 63., 64.,  0., 66., 67., 68., 69.,  0.],\n",
      "          [ 0., 50., 51., 52., 53.,  0., 55., 56., 57., 58.,  0., 60., 61., 62.,\n",
      "           63.,  0., 65., 66., 67., 68.,  0., 70., 71., 72., 73.],\n",
      "          [50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62., 63.,\n",
      "           64., 65., 66., 67., 68., 69., 70., 71., 72., 73., 74.],\n",
      "          [51., 52., 53., 54.,  0., 56., 57., 58., 59.,  0., 61., 62., 63., 64.,\n",
      "            0., 66., 67., 68., 69.,  0., 71., 72., 73., 74.,  0.],\n",
      "          [ 0., 55., 56., 57., 58.,  0., 60., 61., 62., 63.,  0., 65., 66., 67.,\n",
      "           68.,  0., 70., 71., 72., 73.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68.,\n",
      "           69., 70., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.],\n",
      "          [56., 57., 58., 59.,  0., 61., 62., 63., 64.,  0., 66., 67., 68., 69.,\n",
      "            0., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.,  0.]]]])\n",
      "\n",
      "Grouped Patches Split: torch.Size([1, 1, 3, 9, 25])\n",
      "tensor([[[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,\n",
      "             7.,  8.,  0., 10., 11., 12., 13.,  0., 15., 16., 17., 18.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,\n",
      "             8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,\n",
      "             9.,  0., 11., 12., 13., 14.,  0., 16., 17., 18., 19.,  0.],\n",
      "           [ 0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,  7.,  8.,  0., 10., 11.,\n",
      "            12., 13.,  0., 15., 16., 17., 18.,  0., 20., 21., 22., 23.],\n",
      "           [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "            13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.],\n",
      "           [ 1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,  9.,  0., 11., 12., 13.,\n",
      "            14.,  0., 16., 17., 18., 19.,  0., 21., 22., 23., 24.,  0.],\n",
      "           [ 0.,  5.,  6.,  7.,  8.,  0., 10., 11., 12., 13.,  0., 15., 16.,\n",
      "            17., 18.,  0., 20., 21., 22., 23.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17.,\n",
      "            18., 19., 20., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [ 6.,  7.,  8.,  9.,  0., 11., 12., 13., 14.,  0., 16., 17., 18.,\n",
      "            19.,  0., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.,  0.,  0.,  0., 25., 26., 27., 28.,  0., 30., 31.,\n",
      "            32., 33.,  0., 35., 36., 37., 38.,  0., 40., 41., 42., 43.],\n",
      "           [ 0.,  0.,  0.,  0.,  0., 25., 26., 27., 28., 29., 30., 31., 32.,\n",
      "            33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.],\n",
      "           [ 0.,  0.,  0.,  0.,  0., 26., 27., 28., 29.,  0., 31., 32., 33.,\n",
      "            34.,  0., 36., 37., 38., 39.,  0., 41., 42., 43., 44.,  0.],\n",
      "           [ 0., 25., 26., 27., 28.,  0., 30., 31., 32., 33.,  0., 35., 36.,\n",
      "            37., 38.,  0., 40., 41., 42., 43.,  0., 45., 46., 47., 48.],\n",
      "           [25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.,\n",
      "            38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
      "           [26., 27., 28., 29.,  0., 31., 32., 33., 34.,  0., 36., 37., 38.,\n",
      "            39.,  0., 41., 42., 43., 44.,  0., 46., 47., 48., 49.,  0.],\n",
      "           [ 0., 30., 31., 32., 33.,  0., 35., 36., 37., 38.,  0., 40., 41.,\n",
      "            42., 43.,  0., 45., 46., 47., 48.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.,\n",
      "            43., 44., 45., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [31., 32., 33., 34.,  0., 36., 37., 38., 39.,  0., 41., 42., 43.,\n",
      "            44.,  0., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "          [[ 0.,  0.,  0.,  0.,  0.,  0., 50., 51., 52., 53.,  0., 55., 56.,\n",
      "            57., 58.,  0., 60., 61., 62., 63.,  0., 65., 66., 67., 68.],\n",
      "           [ 0.,  0.,  0.,  0.,  0., 50., 51., 52., 53., 54., 55., 56., 57.,\n",
      "            58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
      "           [ 0.,  0.,  0.,  0.,  0., 51., 52., 53., 54.,  0., 56., 57., 58.,\n",
      "            59.,  0., 61., 62., 63., 64.,  0., 66., 67., 68., 69.,  0.],\n",
      "           [ 0., 50., 51., 52., 53.,  0., 55., 56., 57., 58.,  0., 60., 61.,\n",
      "            62., 63.,  0., 65., 66., 67., 68.,  0., 70., 71., 72., 73.],\n",
      "           [50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62.,\n",
      "            63., 64., 65., 66., 67., 68., 69., 70., 71., 72., 73., 74.],\n",
      "           [51., 52., 53., 54.,  0., 56., 57., 58., 59.,  0., 61., 62., 63.,\n",
      "            64.,  0., 66., 67., 68., 69.,  0., 71., 72., 73., 74.,  0.],\n",
      "           [ 0., 55., 56., 57., 58.,  0., 60., 61., 62., 63.,  0., 65., 66.,\n",
      "            67., 68.,  0., 70., 71., 72., 73.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67.,\n",
      "            68., 69., 70., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.],\n",
      "           [56., 57., 58., 59.,  0., 61., 62., 63., 64.,  0., 66., 67., 68.,\n",
      "            69.,  0., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.,  0.]]]]])\n",
      "\n",
      "Reshaped Weights: torch.Size([2, 27])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "Convolved Patches: torch.Size([1, 2, 5, 5])\n",
      "tensor([[[[ 336.,  513.,  531.,  549.,  372.],\n",
      "          [ 549.,  837.,  864.,  891.,  603.],\n",
      "          [ 639.,  972.,  999., 1026.,  693.],\n",
      "          [ 729., 1107., 1134., 1161.,  783.],\n",
      "          [ 516.,  783.,  801.,  819.,  552.]],\n",
      "\n",
      "         [[ 336.,  513.,  531.,  549.,  372.],\n",
      "          [ 549.,  837.,  864.,  891.,  603.],\n",
      "          [ 639.,  972.,  999., 1026.,  693.],\n",
      "          [ 729., 1107., 1134., 1161.,  783.],\n",
      "          [ 516.,  783.,  801.,  819.,  552.]]]])\n",
      "\n",
      "Output with Bias Added: torch.Size([1, 2, 5, 5])\n",
      "tensor([[[[ 336.,  513.,  531.,  549.,  372.],\n",
      "          [ 549.,  837.,  864.,  891.,  603.],\n",
      "          [ 639.,  972.,  999., 1026.,  693.],\n",
      "          [ 729., 1107., 1134., 1161.,  783.],\n",
      "          [ 516.,  783.,  801.,  819.,  552.]],\n",
      "\n",
      "         [[ 336.,  513.,  531.,  549.,  372.],\n",
      "          [ 549.,  837.,  864.,  891.,  603.],\n",
      "          [ 639.,  972.,  999., 1026.,  693.],\n",
      "          [ 729., 1107., 1134., 1161.,  783.],\n",
      "          [ 516.,  783.,  801.,  819.,  552.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import unfold, fold\n",
    "\n",
    "\n",
    "# Example input and parameters\n",
    "batch_size, in_channels, height, width = 1, 3, 5, 5\n",
    "out_channels, kernel_height, kernel_width = 2, 3, 3\n",
    "stride, padding, dilation, groups = 1, 1, 1, 1\n",
    "\n",
    "x = torch.arange(batch_size * in_channels * height * width, dtype=torch.float32).reshape(batch_size, in_channels, height, width)\n",
    "w = torch.ones(out_channels, in_channels // groups, kernel_height, kernel_width)\n",
    "b = torch.zeros(out_channels)\n",
    "\n",
    "print(\"Input (x):\", x.shape)\n",
    "print(x)\n",
    "\n",
    "# Padding, stride, and dilation as tuples\n",
    "padding_h, padding_w = padding, padding\n",
    "stride_h, stride_w = stride, stride\n",
    "dilation_h, dilation_w = dilation, dilation\n",
    "\n",
    "out_height = int((height + 2 * padding_h - dilation_h * (kernel_height - 1) - 1) / stride_h) + 1\n",
    "out_width = int((width + 2 * padding_w - dilation_w * (kernel_width - 1) - 1) / stride_w) + 1\n",
    "\n",
    "# Unfold x\n",
    "patches = unfold(x, (kernel_height, kernel_width), dilation=(dilation_h, dilation_w), padding=(padding_h, padding_w), stride=(stride_h, stride_w))\n",
    "print(\"\\nUnfolded Input (patches):\", patches.shape)\n",
    "print(patches)\n",
    "\n",
    "# Reshape patches for groups\n",
    "\n",
    "patches_re = patches.reshape(batch_size, in_channels, kernel_height * kernel_width, out_height * out_width)\n",
    "print(\"\\nReshaped Patches for Groups:\", patches_re.shape)\n",
    "print(patches_re)\n",
    "\n",
    "# Group splitting\n",
    "patches_group_split = torch.stack(patches_re.chunk(chunks=groups, dim=1), dim=1)\n",
    "print(\"\\nGrouped Patches Split:\", patches_group_split.shape)\n",
    "print(patches_group_split)\n",
    "\n",
    "# Weight splitting and reshaping\n",
    "w_group_split = w.reshape(out_channels, in_channels * kernel_height * kernel_width)\n",
    "print(\"\\nReshaped Weights:\", w_group_split.shape)\n",
    "print(w_group_split)\n",
    "\n",
    "# Convolution as matrix multiplication\n",
    "convolved_patches = w_group_split @ patches_group_split.reshape(batch_size, groups, -1, out_height * out_width)\n",
    "convolved_patches = convolved_patches.reshape(batch_size, out_channels, out_height, out_width)\n",
    "print(\"\\nConvolved Patches:\", convolved_patches.shape)\n",
    "print(convolved_patches)\n",
    "\n",
    "# Add bias\n",
    "convolved_patches += b.reshape(1, -1, 1, 1)\n",
    "print(\"\\nOutput with Bias Added:\", convolved_patches.shape)\n",
    "print(convolved_patches)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27, 25])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 9, 25])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,\n",
       "             7.,  8.,  0., 10., 11., 12., 13.,  0., 15., 16., 17., 18.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,\n",
       "             8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,\n",
       "             9.,  0., 11., 12., 13., 14.,  0., 16., 17., 18., 19.,  0.],\n",
       "           [ 0.,  0.,  1.,  2.,  3.,  0.,  5.,  6.,  7.,  8.,  0., 10., 11.,\n",
       "            12., 13.,  0., 15., 16., 17., 18.,  0., 20., 21., 22., 23.],\n",
       "           [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "            13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.],\n",
       "           [ 1.,  2.,  3.,  4.,  0.,  6.,  7.,  8.,  9.,  0., 11., 12., 13.,\n",
       "            14.,  0., 16., 17., 18., 19.,  0., 21., 22., 23., 24.,  0.],\n",
       "           [ 0.,  5.,  6.,  7.,  8.,  0., 10., 11., 12., 13.,  0., 15., 16.,\n",
       "            17., 18.,  0., 20., 21., 22., 23.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17.,\n",
       "            18., 19., 20., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 6.,  7.,  8.,  9.,  0., 11., 12., 13., 14.,  0., 16., 17., 18.,\n",
       "            19.,  0., 21., 22., 23., 24.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "          [[ 0.,  0.,  0.,  0.,  0.,  0., 25., 26., 27., 28.,  0., 30., 31.,\n",
       "            32., 33.,  0., 35., 36., 37., 38.,  0., 40., 41., 42., 43.],\n",
       "           [ 0.,  0.,  0.,  0.,  0., 25., 26., 27., 28., 29., 30., 31., 32.,\n",
       "            33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.],\n",
       "           [ 0.,  0.,  0.,  0.,  0., 26., 27., 28., 29.,  0., 31., 32., 33.,\n",
       "            34.,  0., 36., 37., 38., 39.,  0., 41., 42., 43., 44.,  0.],\n",
       "           [ 0., 25., 26., 27., 28.,  0., 30., 31., 32., 33.,  0., 35., 36.,\n",
       "            37., 38.,  0., 40., 41., 42., 43.,  0., 45., 46., 47., 48.],\n",
       "           [25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.,\n",
       "            38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
       "           [26., 27., 28., 29.,  0., 31., 32., 33., 34.,  0., 36., 37., 38.,\n",
       "            39.,  0., 41., 42., 43., 44.,  0., 46., 47., 48., 49.,  0.],\n",
       "           [ 0., 30., 31., 32., 33.,  0., 35., 36., 37., 38.,  0., 40., 41.,\n",
       "            42., 43.,  0., 45., 46., 47., 48.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.,\n",
       "            43., 44., 45., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [31., 32., 33., 34.,  0., 36., 37., 38., 39.,  0., 41., 42., 43.,\n",
       "            44.,  0., 46., 47., 48., 49.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "          [[ 0.,  0.,  0.,  0.,  0.,  0., 50., 51., 52., 53.,  0., 55., 56.,\n",
       "            57., 58.,  0., 60., 61., 62., 63.,  0., 65., 66., 67., 68.],\n",
       "           [ 0.,  0.,  0.,  0.,  0., 50., 51., 52., 53., 54., 55., 56., 57.,\n",
       "            58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n",
       "           [ 0.,  0.,  0.,  0.,  0., 51., 52., 53., 54.,  0., 56., 57., 58.,\n",
       "            59.,  0., 61., 62., 63., 64.,  0., 66., 67., 68., 69.,  0.],\n",
       "           [ 0., 50., 51., 52., 53.,  0., 55., 56., 57., 58.,  0., 60., 61.,\n",
       "            62., 63.,  0., 65., 66., 67., 68.,  0., 70., 71., 72., 73.],\n",
       "           [50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62.,\n",
       "            63., 64., 65., 66., 67., 68., 69., 70., 71., 72., 73., 74.],\n",
       "           [51., 52., 53., 54.,  0., 56., 57., 58., 59.,  0., 61., 62., 63.,\n",
       "            64.,  0., 66., 67., 68., 69.,  0., 71., 72., 73., 74.,  0.],\n",
       "           [ 0., 55., 56., 57., 58.,  0., 60., 61., 62., 63.,  0., 65., 66.,\n",
       "            67., 68.,  0., 70., 71., 72., 73.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67.,\n",
       "            68., 69., 70., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [56., 57., 58., 59.,  0., 61., 62., 63., 64.,  0., 66., 67., 68.,\n",
       "            69.,  0., 71., 72., 73., 74.,  0.,  0.,  0.,  0.,  0.,  0.]]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_group_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d(x, kernel_size, padding=0, stride=1, dilation=1, ctx=None):\n",
    "  \"\"\"A differentiable convolution of 2d tensors.\n",
    "\n",
    "  Note: Read this following documentation regarding the output's shape.\n",
    "  https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n",
    "\n",
    "  Backward call:\n",
    "    backward_fn: max_pool2d_backward\n",
    "    args: y, x, padding, stride, dilation\n",
    "\n",
    "  Args:\n",
    "    x (torch.Tensor): The input tensor. Has shape `(batch_size, in_channels, height, width)`.\n",
    "    kernel_size (Tuple[int, int] or int): The kernel size in each dimension (height, width).\n",
    "    padding (Tuple[int, int] or int, Optional): The padding in each dimension (height, width).\n",
    "      Defaults to 0.\n",
    "    stride (Tuple[int, int] or int, Optional): The stride in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    dilation (Tuple[int, int] or int, Optional): The dilation in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    ctx (List, optional): The autograd context. Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    y (torch.Tensor): The output tensor.\n",
    "      Has shape `(batch_size, in_channels, out_height, out_width)`.\n",
    "  \"\"\"\n",
    "  batch_size, in_channels, height, width = x.shape\n",
    "  kernel_y, kernal_x = kernel_size\n",
    "  pad_y, pad_x = _pair(padding) if isinstance(padding, int) else padding\n",
    "  step_y, step_x = _pair(stride) if isinstance(stride, int) else stride\n",
    "  dil_y, dil_x = _pair(dilation) if isinstance(dilation, int) else dilation\n",
    "\n",
    "  out_height = int(1 + ((height + 2 * pad_y - dil_y * (kernel_y - 1) - 1) / step_y))\n",
    "  out_width = int(1 + ((width + 2 * pad_x - dil_x * (kernal_x - 1) - 1) / step_x))\n",
    "\n",
    "  # Unfold x to patches\n",
    "  input_matrix = unfold(x, (kernel_y, kernal_x),\n",
    "                    dilation=dilation,\n",
    "                    padding=padding,\n",
    "                    stride=stride)\n",
    "  input_matrix = input_matrix.reshape(batch_size, in_channels, kernel_y * kernal_x, out_height, out_width)\n",
    "\n",
    "  # Take max over each patch\n",
    "  y, index = input_matrix.max(dim=2)\n",
    "\n",
    "  # Save context for the backward pass\n",
    "  if ctx is not None:\n",
    "      ctx += [(max_pool2d_backward, [y, x, index, kernel_size, padding, stride, dilation])]\n",
    "\n",
    "  return y\n",
    "\n",
    "\n",
    "def max_pool2d_backward(y, x, index, kernel_size, padding, stride, dilation):\n",
    "  \"\"\"Backward computation of `max_pool2d`.\n",
    "\n",
    "  Propagates the gradients of `y` (in `y.grad`) to `x` and accumulates it in `x.grad`.\n",
    "\n",
    "  Args:\n",
    "    y (torch.Tensor): The output tensor.\n",
    "      Has shape `(batch_size, in_channels, out_height, out_width)`.\n",
    "    x (torch.Tensor): The input tensor.\n",
    "      Has shape `(batch_size, in_channels, height, width)`.\n",
    "    index (torch.Tensor): Auxilary tensor with indices of the maximum elements. You are\n",
    "      not restricted to a specific format.\n",
    "    kernel_size (Tuple[int, int] or int): The kernel size in each dimension (height, width).\n",
    "    padding (Tuple[int, int] or int, Optional): The padding in each dimension (height, width).\n",
    "      Defaults to 0.\n",
    "    stride (Tuple[int, int] or int, Optional): The stride in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    dilation (Tuple[int, int] or int, Optional): The dilation in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "  \"\"\"\n",
    "  # Extract and parse input\n",
    "  batch_size, in_channels, height, width = x.shape\n",
    "  batch_size, in_channels, out_height, out_width = y.shape\n",
    "  kernel_y, kernal_x = _pair(kernel_size) if isinstance(kernel_size, int) else kernel_size\n",
    "\n",
    "  # Convert indices to one-hot encoding\n",
    "  one_hot_entries = one_hot(index, num_classes=kernel_y * kernal_x)\n",
    "  one_hot_entries = one_hot_entries.permute([0, 1, 4, 2, 3])\n",
    "\n",
    "  # Compute the gradient w.r.t. unfolded tensor\n",
    "  permuted_x_grad = one_hot_entries * y.grad.unsqueeze(2)\n",
    "  permuted_x_grad = permuted_x_grad.reshape(batch_size, in_channels * kernel_y * kernal_x, out_height * out_width)\n",
    "\n",
    "  # Add gradients to x.grad using fold\n",
    "  x_grad = fold(permuted_x_grad,\n",
    "                output_size=(height, width),\n",
    "                kernel_size=(kernel_y, kernal_x),\n",
    "                dilation=dilation,\n",
    "                padding=padding,\n",
    "                stride=stride)\n",
    "  \n",
    "  # Accumulate the gradients\n",
    "  x.grad += x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d_v2(x, kernel_size, padding=0, stride=1, dilation=1, ctx=None):\n",
    "  \"\"\"A differentiable convolution of 2d tensors.\n",
    "\n",
    "  Note: Read this following documentation regarding the output's shape.\n",
    "  https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d\n",
    "\n",
    "  Backward call:\n",
    "    backward_fn: max_pool2d_backward\n",
    "    args: y, x, padding, stride, dilation\n",
    "\n",
    "  Args:\n",
    "    x (torch.Tensor): The input tensor. Has shape `(batch_size, in_channels, height, width)`.\n",
    "    kernel_size (Tuple[int, int] or int): The kernel size in each dimension (height, width).\n",
    "    padding (Tuple[int, int] or int, Optional): The padding in each dimension (height, width).\n",
    "      Defaults to 0.\n",
    "    stride (Tuple[int, int] or int, Optional): The stride in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    dilation (Tuple[int, int] or int, Optional): The dilation in each dimension (height, width).\n",
    "      Defaults to 1.\n",
    "    ctx (List, optional): The autograd context. Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    y (torch.Tensor): The output tensor.\n",
    "      Has shape `(batch_size, in_channels, out_height, out_width)`.\n",
    "  \"\"\"\n",
    "  # BEGIN SOLUTION\n",
    "  # extract and parse input\n",
    "  batch_size, in_channels, height, width = x.shape\n",
    "  kernel_height, kernel_width = _pair(kernel_size) if type(kernel_size) is int else kernel_size\n",
    "  padding_h, padding_w = _pair(padding) if type(padding) is int else padding\n",
    "  stride_h, stride_w = _pair(stride) if type(stride) is int else stride\n",
    "  dilation_h, dilation_w = _pair(dilation) if type(dilation) is int else dilation\n",
    "  out_height = int(1 + ((height + 2*padding_h - dilation_h * (kernel_height - 1) - 1) / (stride_h)))\n",
    "  out_width = int(1 + ((width + 2*padding_w - dilation_w * (kernel_width - 1) - 1) / (stride_w)))\n",
    "\n",
    "  # unfold x to patches\n",
    "  # patches.shape - (batch_size, C*Kh*Kw, out_height*out_width)\n",
    "  patches = unfold(x, (kernel_height, kernel_width),\n",
    "                    dilation=dilation,\n",
    "                    padding=padding, \n",
    "                    stride=stride)\n",
    "  patches = patches.reshape(batch_size, in_channels, kernel_height*kernel_width, out_height, out_width)\n",
    "\n",
    "  # take max over each patch\n",
    "  y, index = patches.max(dim=2)\n",
    "\n",
    "  if ctx is not None:\n",
    "    ctx += [(max_pool2d_backward, [y, x, index, kernel_size, padding, stride, dilation])]\n",
    "\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3, 4, 4]' is invalid for input of size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     19\u001b[0m dilation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 21\u001b[0m y1 \u001b[38;5;241m=\u001b[39m max_pool2d_v1(x, kernel_size, padding, stride, dilation)\n\u001b[0;32m     22\u001b[0m y2 \u001b[38;5;241m=\u001b[39m max_pool2d_v2(x, kernel_size, padding, stride, dilation)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(y1)\n",
      "Cell \u001b[1;32mIn[57], line 34\u001b[0m, in \u001b[0;36mmax_pool2d_v1\u001b[1;34m(x, kernel_size, padding, stride, dilation, ctx)\u001b[0m\n\u001b[0;32m     32\u001b[0m out_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m ((height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mpadding_h \u001b[38;5;241m-\u001b[39m dilation_h \u001b[38;5;241m*\u001b[39m (kernel_height \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (stride_h)))\n\u001b[0;32m     33\u001b[0m out_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m ((width \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mpadding_w \u001b[38;5;241m-\u001b[39m dilation_w \u001b[38;5;241m*\u001b[39m (kernel_width \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (stride_w)))\n\u001b[1;32m---> 34\u001b[0m max_vals \u001b[38;5;241m=\u001b[39m max_vals\u001b[38;5;241m.\u001b[39mview(batch_size, in_channels, out_height, out_width)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m   ctx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(max_pool2d_backward, [max_vals, x, max_indices, kernel_size, padding, stride, dilation])]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 3, 4, 4]' is invalid for input of size 12"
     ]
    }
   ],
   "source": [
    "# test both implementations:\n",
    "x = torch.tensor([[[[1., 2., 3., 4.],\n",
    "                    [5., 6., 7., 8.],\n",
    "                    [9., 10., 11., 12.],\n",
    "                    [13., 14., 15., 16.]],\n",
    "                   [[17., 18., 19., 20.],\n",
    "                    [21., 22., 23., 24.],\n",
    "                    [25., 26., 27., 28.],\n",
    "                    [29., 30., 31., 32.]],\n",
    "                   [[33., 34., 35., 36.],\n",
    "                    [37., 38., 39., 40.],\n",
    "                    [41., 42., 43., 44.],\n",
    "                    [45., 46., 47., 48.]]]])\n",
    "\n",
    "kernel_size = 2\n",
    "padding = 0\n",
    "\n",
    "stride = 2\n",
    "dilation = 1\n",
    "\n",
    "y1 = max_pool2d_v1(x, kernel_size, padding, stride, dilation)\n",
    "y2 = max_pool2d_v2(x, kernel_size, padding, stride, dilation)\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course",
   "language": "python",
   "name": "dl_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
